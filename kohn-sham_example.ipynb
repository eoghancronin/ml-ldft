{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb781422-f1b3-4928-b7dd-2b1c66ddceed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 11:21:23.410338: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-14 11:21:23.678267: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-14 11:21:23.679700: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-14 11:21:24.525503: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tools import semilocaldensities, semilocaldensities_flipped, solve_nonint\n",
    "import time\n",
    "\n",
    "L=24\n",
    "a=1 #non-locality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e57bdb8d-6060-49bd-a8ac-0599dbc0a373",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Loading the disorder configurations v, and the corresponding exact ground state quantities #############\n",
    "\n",
    "with open('data_json/exact_data/L'+str(L)+'_num1000.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "data = {'L':data['L'],\n",
    "         'num':data['num'],\n",
    "         'n_up':np.array(data['n_up']),\n",
    "         'n_dn':np.array(data['n_dn']),\n",
    "         'e_mb':np.array(data['e_mb']),\n",
    "         'v':np.array(data['v']),\n",
    "         'e_hxc':np.array(data['e_hxc']),\n",
    "         'v_hxc':np.array(data['v_hxc']),\n",
    "         'norm_tol':np.array(data['norm_tol']),\n",
    "         'reverse_engineering_error':np.array(data['reverse_engineering_error'])\n",
    "    }\n",
    "n_dmrg = (data['n_up'] + data['n_dn'])/2\n",
    "v = data['v']\n",
    "e_dmrg = data['e_mb']\n",
    "e_hxc_dmrg = data['e_hxc']\n",
    "v_hxc_dmrg = data['v_hxc']\n",
    "num=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66cc7e6d-ce2d-40d6-9830-58e4d933c87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm = tf.keras.layers.Lambda(lambda x: x - tf.math.reduce_mean(x, axis = 1)[:,None])    \n",
    "\n",
    "def construct_network(L, a):\n",
    "    n = 64\n",
    "    inputs_list = [Input(shape=((4*a+2))) for i in range(L+2*a)]\n",
    "    d1 = Dense(n) ;d2 = Dense(n); d3 = Dense(n); d4 = Dense(n); d5 = Dense(n); d6 = Dense(1)\n",
    "    a1 = tf.keras.layers.ELU()\n",
    "    elist = [d6(a1(d5(a1(d4(a1(d3(a1(d2(a1(d1(i))))))))))) for i in inputs_list]\n",
    "    s = tf.keras.layers.add([i for i in elist])\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = 3E-4)\n",
    "    model = Model(inputs = inputs_list, outputs = s)\n",
    "    model.compile(optimizer = opt, loss = 'MAE')\n",
    "    model.load_weights('trained_weights/a'+str(a)+'_n64sym.h5')\n",
    "    return model\n",
    "\n",
    "############### Mixing function, decays linearly with number of iterations, stops decaying after b iterations and stays at a value c ############\n",
    "\n",
    "def mix_f(a,b,c,x):\n",
    "    if x <= b:\n",
    "        return c + a*(1 - x/b)\n",
    "    else:\n",
    "        return c\n",
    "\n",
    "############## Solves the Kohn-Sham equations for the each of the disorder configuartions ################\n",
    "\n",
    "def ks_scheme(V, delta, max_its, N,model,L,a):\n",
    "    rm = tf.keras.layers.Lambda(lambda x: x - tf.math.reduce_mean(x, axis = 1)[:,None])\n",
    "    num = len(V)\n",
    "    n0 = np.repeat(N[:,None]/L,L,1)\n",
    "    n1 = np.repeat(N[:,None]/L,L,1)\n",
    "    successlist = np.repeat(np.array([False]), num)\n",
    "    etalist = np.zeros(num)\n",
    "    itslist = np.zeros(num)\n",
    "    elist = np.zeros(num)\n",
    "    n = tf.convert_to_tensor(semilocaldensities(L,a,n0))\n",
    "    nf = tf.convert_to_tensor(semilocaldensities_flipped(L,a,n0))\n",
    "    with tf.GradientTape(persistent=True) as t:\n",
    "        t.watch(n)\n",
    "        s = model([x for x in n])\n",
    "    grads = t.gradient(s, n)\n",
    "    with tf.GradientTape(persistent=True) as t:\n",
    "        t.watch(nf)\n",
    "        sf = model([x for x in nf])\n",
    "    gradsf = t.gradient(sf, nf)\n",
    "    vxc = tf.transpose(tf.convert_to_tensor([tf.keras.layers.Add()([grads[i+j][:,-1-j] for j in range(2*a+1)]) for i in range(L)]))\n",
    "    vxc= rm(vxc) ; vxc = vxc.numpy()\n",
    "    vxcf= tf.transpose(tf.convert_to_tensor([tf.keras.layers.Add()([gradsf[i+j][:,j] for j in range(2*a+1)]) for i in range(L)]))\n",
    "    vxcf= rm(vxcf) ; vxcf = vxcf.numpy()\n",
    "    vxc = vxc+vxcf\n",
    "\n",
    "    veff = V + vxc\n",
    "    \n",
    "    for b in np.where(successlist == False)[0]:\n",
    "        data = solve_nonint(veff[b], N[b], L)\n",
    "        n1[b] = data[0]\n",
    "        etalist[b] = np.sqrt(np.dot(n1[b]-n0[b],n1[b]-n0[b]))\n",
    "    its = 0\n",
    "    while (its < max_its) & ((successlist.all()) == False):\n",
    "        t1 = time.time()\n",
    "        mix = mix_f(0.025, 2000, 0.005, its)\n",
    "        n0 = (1-mix)*n0 + mix*n1\n",
    "        t3 = time.time()\n",
    "        idx = np.where(successlist==False)[0]\n",
    "        n = tf.convert_to_tensor(semilocaldensities(L,a,n0[idx]))\n",
    "        nf = tf.convert_to_tensor(semilocaldensities_flipped(L,a,n0[idx]))\n",
    "        with tf.GradientTape(persistent=True) as t:\n",
    "            t.watch(n)\n",
    "            t.watch(nf)\n",
    "            s = model([x for x in n])\n",
    "            sf = model([x for x in nf])\n",
    "        grads = t.gradient(s, n)\n",
    "        gradsf = t.gradient(sf, nf)\n",
    "        vxc = tf.transpose(tf.convert_to_tensor([tf.keras.layers.Add()([grads[i+j][:,-1-j] for j in range(2*a+1)]) for i in range(L)]))\n",
    "        vxc= rm(vxc) ; vxc = vxc.numpy()\n",
    "        vxcf= tf.transpose(tf.convert_to_tensor([tf.keras.layers.Add()([gradsf[i+j][:,j] for j in range(2*a+1)]) for i in range(L)]))\n",
    "        vxcf= rm(vxcf) ; vxcf = vxcf.numpy()\n",
    "        vxc = vxc+vxcf\n",
    "        exc = (s + sf).numpy()[:,0]\n",
    "        veff = V[idx] + vxc\n",
    "        #print('t_vxc ', time.time() - t3)\n",
    "        t1 = time.time()\n",
    "        its+=1\n",
    "        for c, b in enumerate(idx):\n",
    "            data = solve_nonint(veff[c], N[b], L) # This eigensolver only uses one thread, some improvement could be made here\n",
    "            n1[b] = data[0]\n",
    "            etalist[b] = np.sqrt(np.dot(n1[b]-n0[b],n1[b]-n0[b]))\n",
    "            itslist[b] +=1\n",
    "            elist[b] = 2*(data[1] - np.dot(data[0], veff[c])) + exc[c]\n",
    "            if etalist[b] < delta:\n",
    "                successlist[b] =True\n",
    "        #print('t_diag', time.time()-t1)\n",
    "        if its%50 == 0:\n",
    "            print('iteration '+str(its)+'/'+str(max_its))\n",
    "            print('converged points '+str(sum(successlist))+'/'+str(num))\n",
    "            print('least converged datapoint', np.max(etalist))\n",
    "            #print('min ', np.min(etalist))\n",
    "            print(' ')\n",
    "    n = tf.convert_to_tensor(semilocaldensities(L,a,n0))\n",
    "    nf = tf.convert_to_tensor(semilocaldensities_flipped(L,a,n0))\n",
    "    with tf.GradientTape(persistent=True) as t:\n",
    "        t.watch(n)\n",
    "        t.watch(nf)\n",
    "        s = model([x for x in n])\n",
    "        sf = model([x for x in nf])\n",
    "    grads = t.gradient(s, n)\n",
    "    gradsf = t.gradient(sf, nf)\n",
    "    vxc = tf.transpose(tf.convert_to_tensor([tf.keras.layers.Add()([grads[i+j][:,-1-j] for j in range(2*a+1)]) for i in range(L)]))\n",
    "    vxc= rm(vxc) ; vxc = vxc.numpy()\n",
    "    vxcf= tf.transpose(tf.convert_to_tensor([tf.keras.layers.Add()([gradsf[i+j][:,j] for j in range(2*a+1)]) for i in range(L)]))\n",
    "    vxcf= rm(vxcf) ; vxcf = vxcf.numpy()\n",
    "    vxc = (vxc+vxcf)\n",
    "    exc = (s + sf).numpy()[:,0]\n",
    "    return (n0, elist, successlist, etalist, itslist, vxc, exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "127b1a0e-1b6d-4ffa-b8a5-8284e9c78289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 50/1000\n",
      "converged points 0/1000\n",
      "least converged datapoint 0.11390394423106903\n",
      " \n",
      "iteration 100/1000\n",
      "converged points 0/1000\n",
      "least converged datapoint 0.027348786670813585\n",
      " \n",
      "iteration 150/1000\n",
      "converged points 0/1000\n",
      "least converged datapoint 0.09855197632402493\n",
      " \n",
      "iteration 200/1000\n",
      "converged points 15/1000\n",
      "least converged datapoint 0.1723611636819302\n",
      " \n",
      "iteration 250/1000\n",
      "converged points 115/1000\n",
      "least converged datapoint 0.1557874841505266\n",
      " \n",
      "iteration 300/1000\n",
      "converged points 318/1000\n",
      "least converged datapoint 0.13630091100025113\n",
      " \n",
      "iteration 350/1000\n",
      "converged points 624/1000\n",
      "least converged datapoint 0.11302610998640307\n",
      " \n",
      "iteration 400/1000\n",
      "converged points 840/1000\n",
      "least converged datapoint 0.08364087248133799\n",
      " \n",
      "iteration 450/1000\n",
      "converged points 949/1000\n",
      "least converged datapoint 0.042624432086470515\n",
      " \n",
      "iteration 500/1000\n",
      "converged points 990/1000\n",
      "least converged datapoint 0.006350765556579004\n",
      " \n",
      "iteration 550/1000\n",
      "converged points 998/1000\n",
      "least converged datapoint 0.0001235251878872393\n",
      " \n",
      "iteration 600/1000\n",
      "converged points 999/1000\n",
      "least converged datapoint 3.7353793711648855e-05\n",
      " \n",
      "iteration 650/1000\n",
      "converged points 999/1000\n",
      "least converged datapoint 1.5152349404325756e-05\n",
      " \n",
      "318.77949833869934\n",
      "e_mae =  0.0011600959493723118\n",
      "e_hxc_mae =  0.0006716419464428383\n",
      "n_mae =  0.0044461610274568525\n",
      "v_hxc_mae =  0.024357462932303918\n"
     ]
    }
   ],
   "source": [
    "model = construct_network(L,a)\n",
    "delta = 1E-5 \n",
    "max_its = 1000 # I usually let it run for longer, not necessary here\n",
    "t1 = time.time() # Should take 673 iterations, about 7 minutes (using the a=1 functional)\n",
    "ksdata = ks_scheme(v, delta, max_its,(L//3)*np.ones(num, dtype = np.int32), model,L,a)\n",
    "print(time.time()-t1)\n",
    "\n",
    "e_mlks = ksdata[1]\n",
    "n_mlks = ksdata[0]\n",
    "v_hxc_mlks = ksdata[-2]\n",
    "e_hxc_mlks = ksdata[-1]\n",
    "e_mae = np.mean(np.abs(e_mlks - e_dmrg))/L # MAE per site\n",
    "n_mae = np.mean(np.abs(n_mlks - n_dmrg))\n",
    "e_hxc_mae = np.mean(np.abs(e_hxc_mlks - e_hxc_dmrg))/L\n",
    "v_hxc_mae = np.mean(np.abs(v_hxc_mlks - v_hxc_dmrg))\n",
    "\n",
    "print('e_mae = ', e_mae)\n",
    "print('e_hxc_mae = ', e_hxc_mae)\n",
    "print('n_mae = ', n_mae)\n",
    "print('v_hxc_mae = ', v_hxc_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e93242-3cde-41a4-8da2-39e3dfa29247",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
